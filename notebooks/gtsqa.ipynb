{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f865ccf",
   "metadata": {},
   "source": [
    "#### Copyright (c) 2025 Graphcore Ltd. All rights reserved.\n",
    "\n",
    "## GTSQA\n",
    "\n",
    "Post-processing used to produce the final version of GTSQA, from the data generated with `synth_kgqa`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47550dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path as osp\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0df1414",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "ogbl-wikig2 (preprocessed as in `notebooks/preprocess_wikikg2.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a4cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikikg2_path = \"../data/ogbl_wikikg2/\"\n",
    "\n",
    "node_qids = np.load(\n",
    "    wikikg2_path + \"node_ids.npy\",\n",
    "    allow_pickle=True,\n",
    ")\n",
    "relation_pids = np.load(\n",
    "    wikikg2_path + \"relation_ids.npy\",\n",
    "    allow_pickle=True,\n",
    ")\n",
    "\n",
    "node_labels = np.load(\n",
    "    wikikg2_path + \"node_labels.npy\",\n",
    "    allow_pickle=True,\n",
    ")\n",
    "relation_labels = np.load(\n",
    "    wikikg2_path + \"relation_labels.npy\",\n",
    "    allow_pickle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e728dd1",
   "metadata": {},
   "source": [
    "Train and test datasets, in the structure of the outputs of `synth-kgqa/process_qa.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c3382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30477, 1622)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = json.load(\n",
    "    open(\n",
    "        \"../data/train.jsonl\",\n",
    "        \"rb\",\n",
    "    )\n",
    ")\n",
    "test_ds = json.load(\n",
    "    open(\n",
    "        \"../data/test.jsonl\",\n",
    "        \"rb\",\n",
    "    )\n",
    ")\n",
    "\n",
    "len(train_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3055eb",
   "metadata": {},
   "source": [
    "## Process datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eab097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(ds, split):\n",
    "    ds_processed = []\n",
    "    for dp in tqdm(ds):\n",
    "        minimal_s_and_q = dict()\n",
    "        seeds = [node_qids[i] for i in dp[\"seed_nodes_id\"]]\n",
    "        minimal_len = 99999\n",
    "        for s, queries in dp[\"minimal_query_per_seed\"].items():\n",
    "            for q in queries:\n",
    "                q_seeds = tuple(set([a for a in seeds if \"wd:\" + a in q]))\n",
    "                if len(q_seeds) < minimal_len:\n",
    "                    minimal_len = len(q_seeds)\n",
    "                    minimal_s_and_q = dict()\n",
    "                if len(q_seeds) <= minimal_len:\n",
    "                    minimal_s_and_q[q_seeds] = q\n",
    "\n",
    "        ans_subgraph = []\n",
    "        for h, r, t in dp[\"answer_subgraph\"]:\n",
    "            ans_subgraph.append(\n",
    "                [\n",
    "                    node_labels[h] + f\" ({node_qids[h]})\",\n",
    "                    relation_labels[r] + f\" ({relation_pids[r]})\",\n",
    "                    node_labels[t] + f\" ({node_qids[t]})\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        dp_clean = {\n",
    "            \"id\": dp[\"id\"],\n",
    "            \"question\": dp[\"question\"],\n",
    "            \"paraphrased_question\": (\n",
    "                dp[\"paraphrased_question\"] if split == \"train\" else None\n",
    "            ),\n",
    "            \"seed_entities\": dp[\"seed_nodes\"],\n",
    "            \"answer_node\": dp[\"answer_node\"],\n",
    "            \"answer_subgraph\": ans_subgraph,\n",
    "            \"sparql_query\": dp[\"sparql_query\"],\n",
    "            \"all_answers_wikidata\": dp[\"all_answers\"],\n",
    "            \"full_answer_subgraph_wikidata\": dp[\"full_subgraph\"],\n",
    "            \"all_answers_wikikg2\": dp[\"all_answers_wikikg2\"],\n",
    "            \"full_answer_subgraph_wikikg2\": dp[\"full_subgraph_wikikg2\"],\n",
    "            \"n_hops\": dp[\"n_hops\"],\n",
    "            \"graph_isomorphism\": dp[\"graph_template\"],\n",
    "            \"redundant\": dp[\"redundant\"],\n",
    "            \"minimal_graph_isomorphism\": dp[\"minimal_graph_templates\"],\n",
    "            \"minimal_seeds_and_queries\": {\n",
    "                \"-\".join(k): v for k, v in minimal_s_and_q.items()\n",
    "            },\n",
    "            \"test_type\": dp[\"test_type\"] if split == \"test\" else [\"training\"],\n",
    "        }\n",
    "\n",
    "        ds_processed.append(dp_clean)\n",
    "    return ds_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d161ed4",
   "metadata": {},
   "source": [
    "### Train set\n",
    "Processed in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873fdcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30477/30477 [00:01<00:00, 15704.42it/s]\n"
     ]
    }
   ],
   "source": [
    "train_clean = process_dataset(train_ds, split=\"train\")\n",
    "train_df = pd.DataFrame(train_clean)\n",
    "train_df[\"minimal_seeds_and_queries\"] = train_df[\"minimal_seeds_and_queries\"].astype(\n",
    "    str\n",
    ")\n",
    "train_df.to_parquet(\"../HF_GTSQA/gtsqa/train.parquet\")\n",
    "\n",
    "\n",
    "N_BLOCKS = 22\n",
    "block_size = int(np.ceil(88 / N_BLOCKS))\n",
    "\n",
    "k = 0\n",
    "block_start = 0\n",
    "for b in range(N_BLOCKS):\n",
    "    block_tot = 0\n",
    "    for i in range(block_size):\n",
    "        partial_res = []\n",
    "        file_name = f\"../data/train.jsonl_scores_{b*block_size + i}.pkl\"  # outputs of synth-kgqa/compute_neighs_and_sp.py (chunked)\n",
    "        if not osp.exists(file_name):\n",
    "            continue\n",
    "        print(f\"Processing {file_name}\")\n",
    "        for sample_scores in pickle.load(open(file_name, \"rb\")):\n",
    "            partial_res.append(sample_scores)\n",
    "        for sample_scores in tqdm(partial_res):\n",
    "            assert train_clean[k][\"id\"] == sample_scores[\"id\"]\n",
    "            text_list = []\n",
    "            for h, r, t in zip(\n",
    "                sample_scores[\"h_id_list\"],\n",
    "                sample_scores[\"r_id_list\"],\n",
    "                sample_scores[\"t_id_list\"],\n",
    "            ):\n",
    "                text_list.append(\n",
    "                    [\n",
    "                        node_labels[h] + f\" ({node_qids[h]})\",\n",
    "                        relation_labels[r] + f\" ({relation_pids[r]})\",\n",
    "                        node_labels[t] + f\" ({node_qids[t]})\",\n",
    "                    ]\n",
    "                )\n",
    "            train_clean[k].update({\"graph\": text_list})\n",
    "            k += 1\n",
    "        block_tot += len(partial_res)\n",
    "    block_clean = train_clean[block_start : block_start + block_tot]\n",
    "    save_path = f\"../HF_GTSQA/gtsqa-with-graphs/train-{'{:05d}'.format(b)}-of-{'{:05d}'.format(N_BLOCKS)}.parquet\"\n",
    "    print(f\"Saving span {block_start}--{block_start+block_tot} to {save_path}\")\n",
    "    block_df = pd.DataFrame(block_clean)\n",
    "    block_df[\"minimal_seeds_and_queries\"] = block_df[\n",
    "        \"minimal_seeds_and_queries\"\n",
    "    ].astype(str)\n",
    "    block_df.to_parquet(save_path)\n",
    "    block_start = block_start + block_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916e5069",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b5867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1622/1622 [00:00<00:00, 66666.94it/s]\n"
     ]
    }
   ],
   "source": [
    "test_clean = process_dataset(test_ds, split=\"test\")\n",
    "\n",
    "test_ds_scores = pickle.load(\n",
    "    open(\"../data/test_scores.pkl\", \"rb\")\n",
    ")  # output of synth-kgqa/compute_neighs_and_sp.py\n",
    "\n",
    "test_df = pd.DataFrame(test_clean)\n",
    "test_df[\"minimal_seeds_and_queries\"] = train_df[\"minimal_seeds_and_queries\"].astype(str)\n",
    "test_df.to_parquet(\"../HF_GTSQA/gtsqa/test.parquet\")\n",
    "\n",
    "for sample, sample_scores in tqdm(\n",
    "    zip(test_clean, test_ds_scores), total=len(test_clean)\n",
    "):\n",
    "    assert sample[\"id\"] == sample_scores[\"id\"]\n",
    "    text_list = []\n",
    "    for h, r, t in zip(\n",
    "        sample_scores[\"h_id_list\"],\n",
    "        sample_scores[\"r_id_list\"],\n",
    "        sample_scores[\"t_id_list\"],\n",
    "    ):\n",
    "        text_list.append(\n",
    "            [\n",
    "                node_labels[h] + f\" ({node_qids[h]})\",\n",
    "                relation_labels[r] + f\" ({relation_pids[r]})\",\n",
    "                node_labels[t] + f\" ({node_qids[t]})\",\n",
    "            ]\n",
    "        )\n",
    "    sample.update({\"graph\": text_list})\n",
    "\n",
    "test_df = pd.DataFrame(test_clean)\n",
    "test_df[\"minimal_seeds_and_queries\"] = test_df[\"minimal_seeds_and_queries\"].astype(str)\n",
    "test_df.to_parquet(\"../HF_GTSQA/gtsqa-with-graphs/test-00000-of-00001.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
